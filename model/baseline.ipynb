{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccfd2998-76a3-498d-85d3-ad376140355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, MultinomialNB\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f1ed939-7823-4489-82f0-c1e9210899f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>agency</th>\n",
       "      <th>humanComparison</th>\n",
       "      <th>hyperbole</th>\n",
       "      <th>historyComparison</th>\n",
       "      <th>unjustClaims</th>\n",
       "      <th>deepSounding</th>\n",
       "      <th>sceptics</th>\n",
       "      <th>deEmphasize</th>\n",
       "      <th>performanceNumber</th>\n",
       "      <th>inscrutable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>The AI that can tell if a sheep is in PAIN: Re...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Can YOU spot the difference? Damaged artworks ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>SoftBank-backed Tokopedia bets on logistics, A...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  agency  \\\n",
       "523  The AI that can tell if a sheep is in PAIN: Re...    True   \n",
       "405  Can YOU spot the difference? Damaged artworks ...   False   \n",
       "629  SoftBank-backed Tokopedia bets on logistics, A...   False   \n",
       "\n",
       "     humanComparison  hyperbole  historyComparison  unjustClaims  \\\n",
       "523            False      False              False         False   \n",
       "405            False      False              False         False   \n",
       "629            False      False              False         False   \n",
       "\n",
       "     deepSounding  sceptics  deEmphasize  performanceNumber  inscrutable  \n",
       "523         False     False         True              False        False  \n",
       "405         False     False         True              False        False  \n",
       "629         False     False        False              False        False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = defaultdict(list)\n",
    "path = Path(\"data/data.json\")\n",
    "\n",
    "with open(path) as f:\n",
    "    d = json.load(f)\n",
    "    for e in d[\"data\"]:\n",
    "        for k, v in e.items():\n",
    "            dataset[k].append(v)\n",
    "\n",
    "df = pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6185ac4a-a5d1-4c1a-be96-9ad178db028f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agency',\n",
       " 'humanComparison',\n",
       " 'hyperbole',\n",
       " 'historyComparison',\n",
       " 'unjustClaims',\n",
       " 'deepSounding',\n",
       " 'sceptics',\n",
       " 'deEmphasize',\n",
       " 'performanceNumber',\n",
       " 'inscrutable']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [k for k in df.columns if k not in [\"text\"]]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f256e7f-97eb-4c57-bb90-a37cee2dfe47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A',\n",
       "  'new',\n",
       "  'vision',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'for',\n",
       "  'the',\n",
       "  'people'],\n",
       " ['The', 'gig', 'workers', 'fighting', 'back', 'against', 'the', 'algorithms']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text\"] = list(map(lambda text: word_tokenize(text), dataset[\"text\"]))\n",
    "\n",
    "dataset[\"text\"][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a7628b7-9041-4575-8cf2-217cf52534d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(571,)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, random_state=42, test_size=0.2, shuffle=True)\n",
    "\n",
    "X_train = train.text\n",
    "X_test = test.text\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "476fcc8c-69e0-4dd8-b526-b860412ae8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing agency\n",
      "Test accuracy is 0.7762237762237763\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing humanComparison\n",
      "Test accuracy is 0.8671328671328671\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing hyperbole\n",
      "Test accuracy is 0.9090909090909091\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing historyComparison\n",
      "Test accuracy is 0.993006993006993\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing unjustClaims\n",
      "Test accuracy is 0.9370629370629371\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing deepSounding\n",
      "Test accuracy is 0.958041958041958\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing sceptics\n",
      "Test accuracy is 0.993006993006993\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing deEmphasize\n",
      "Test accuracy is 0.8671328671328671\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing performanceNumber\n",
      "Test accuracy is 0.972027972027972\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing inscrutable\n",
      "Test accuracy is 0.958041958041958\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline combining a text feature extractor with multi lable classifier\n",
    "NB_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"tfidf\", TfidfVectorizer(stop_words=stop_words)),\n",
    "        (\"clf\", OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None))),\n",
    "    ]\n",
    ")\n",
    "for label in labels:\n",
    "    print(\"... Processing {}\".format(label))\n",
    "    # train the model using X_dtm & y\n",
    "    NB_pipeline.fit(X_train, train[label])\n",
    "    # compute the testing accuracy\n",
    "    prediction = NB_pipeline.predict(X_test)\n",
    "    print(f\"\"\"Test accuracy is {accuracy_score(test[label], prediction)}\n",
    "Test precision is {precision_score(test[label], prediction, zero_division=0)}\n",
    "Test recall is {recall_score(test[label], prediction)}\n",
    "Test f1 is {f1_score(test[label], prediction)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "291b0397-653b-437d-ad2e-3ebf3dabf4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing agency\n",
      "Test accuracy is 0.7412587412587412\n",
      "Test precision is 0.35294117647058826\n",
      "Test recall is 0.1875\n",
      "Test f1 is 0.24489795918367344\n",
      "\n",
      "... Processing humanComparison\n",
      "Test accuracy is 0.8671328671328671\n",
      "Test precision is 0.5\n",
      "Test recall is 0.10526315789473684\n",
      "Test f1 is 0.17391304347826086\n",
      "\n",
      "... Processing hyperbole\n",
      "Test accuracy is 0.9020979020979021\n",
      "Test precision is 0.3333333333333333\n",
      "Test recall is 0.07692307692307693\n",
      "Test f1 is 0.125\n",
      "\n",
      "... Processing historyComparison\n",
      "Test accuracy is 0.993006993006993\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing unjustClaims\n",
      "Test accuracy is 0.9440559440559441\n",
      "Test precision is 1.0\n",
      "Test recall is 0.1111111111111111\n",
      "Test f1 is 0.19999999999999998\n",
      "\n",
      "... Processing deepSounding\n",
      "Test accuracy is 0.958041958041958\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing sceptics\n",
      "Test accuracy is 0.993006993006993\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing deEmphasize\n",
      "Test accuracy is 0.8881118881118881\n",
      "Test precision is 0.7142857142857143\n",
      "Test recall is 0.2631578947368421\n",
      "Test f1 is 0.3846153846153846\n",
      "\n",
      "... Processing performanceNumber\n",
      "Test accuracy is 0.972027972027972\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing inscrutable\n",
      "Test accuracy is 0.958041958041958\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVC_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"tfidf\", TfidfVectorizer(stop_words=stop_words)),\n",
    "        (\"clf\", OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "    ]\n",
    ")\n",
    "for label in labels:\n",
    "    print(\"... Processing {}\".format(label))\n",
    "    # train the model using X_dtm & y\n",
    "    SVC_pipeline.fit(X_train, train[label])\n",
    "    # compute the testing accuracy\n",
    "    prediction = SVC_pipeline.predict(X_test)\n",
    "    print(f\"\"\"Test accuracy is {accuracy_score(test[label], prediction)}\n",
    "Test precision is {precision_score(test[label], prediction, zero_division=0)}\n",
    "Test recall is {recall_score(test[label], prediction)}\n",
    "Test f1 is {f1_score(test[label], prediction)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c60cc8c-746a-4297-ac2f-97547e355250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing agency\n",
      "Test accuracy is 0.7832167832167832\n",
      "Test precision is 1.0\n",
      "Test recall is 0.03125\n",
      "Test f1 is 0.06060606060606061\n",
      "\n",
      "... Processing humanComparison\n",
      "Test accuracy is 0.8671328671328671\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing hyperbole\n",
      "Test accuracy is 0.9090909090909091\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing historyComparison\n",
      "Test accuracy is 0.993006993006993\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing unjustClaims\n",
      "Test accuracy is 0.9370629370629371\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing deepSounding\n",
      "Test accuracy is 0.958041958041958\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing sceptics\n",
      "Test accuracy is 0.993006993006993\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing deEmphasize\n",
      "Test accuracy is 0.8671328671328671\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing performanceNumber\n",
      "Test accuracy is 0.972027972027972\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n",
      "... Processing inscrutable\n",
      "Test accuracy is 0.958041958041958\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1 is 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "LogReg_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"tfidf\", TfidfVectorizer(stop_words=stop_words)),\n",
    "        (\"clf\", OneVsRestClassifier(LogisticRegression(solver=\"sag\"), n_jobs=1)),\n",
    "    ]\n",
    ")\n",
    "for label in labels:\n",
    "    print(\"... Processing {}\".format(label))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline.fit(X_train, train[label])\n",
    "    # compute the testing accuracy\n",
    "    prediction = LogReg_pipeline.predict(X_test)\n",
    "    print(f\"\"\"Test accuracy is {accuracy_score(test[label], prediction)}\n",
    "Test precision is {precision_score(test[label], prediction, zero_division=0)}\n",
    "Test recall is {recall_score(test[label], prediction)}\n",
    "Test f1 is {f1_score(test[label], prediction)}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
