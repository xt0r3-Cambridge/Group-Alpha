{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79688b38-ed00-4f35-b491-6a41e2433a6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# One-vs-Rest Classifier\n",
    "\n",
    "This notebook implements an one-vs-rest classifier that fine-tunes several BERT models to tell if a sentence contains problematic metaphors.\n",
    "\n",
    "<div hidden>\n",
    "TODO: add extend data3/data.json with better data in the same format that actually makes sense.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c329b4-dc31-4cd0-8058-b59015328184",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f0b50b-c9ff-45b5-979a-c2fa5634ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -U\n",
    "!pip install sklearn -U\n",
    "!pip install datasets -U\n",
    "!pip install torch -U\n",
    "!pip install numpy -U\n",
    "!pip install evaluate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01c2eb7-f752-4628-b88d-48576c6461ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from transformers import (\n",
    "    BertForNextSentencePrediction,\n",
    "    BertTokenizer,\n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c78698-ce72-41f7-96fb-111a4f1d3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"aihype_bert_fine_tune\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ae221-1bbc-4a4a-8a1e-0feb9d17b57e",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898408be-0c15-4e58-9e7e-97fffccb4797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-631b12db7123e476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/xt0r3/.cache/huggingface/datasets/json/default-631b12db7123e476/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb75afd7d2a440d682aa9ff813016e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ba0482b6ae4853ad716034c0dc0066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/xt0r3/.cache/huggingface/datasets/json/default-631b12db7123e476/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8252bb392ac448759e33e97e0492b6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sen1', 'sen2', 'ans'],\n",
       "        num_rows: 251461\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"data/pairs_unlabelled.json\", field=\"data\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b214393b-11e3-454e-b21f-a05ee38fefbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sen1': ['Not one savings account is currently able to keep anywhere near the pace of rising costs .',\n",
       "  'People can be forgiven for losing interest and whether there is a point of tucking money away for interest paying in some circumstances 5 per cent below the rate of inflation - and this gap could grow bigger in the coming months .',\n",
       "  'However , firstly for those without a savings pot whatsoever , it is important to have a rainy day fund to fall back on .'],\n",
       " 'sen2': ['By Ed Magnus For Thisismoney.co.uk Published : 07:50 , 13 January 2022 | Updated : 19:04 , 13 January 2022 8 View comments Surging inflation means the outlook for savers hunting returns is bleaker than bleak .',\n",
       "  'Not one savings account is currently able to keep anywhere near the pace of rising costs .',\n",
       "  'People can be forgiven for losing interest and whether there is a point of tucking money away for interest paying in some circumstances 5 per cent below the rate of inflation - and this gap could grow bigger in the coming months .'],\n",
       " 'ans': [0, 0, 0]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce458fc2-c419-4b3c-b4aa-14571f7467e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514633be-491c-4f3c-a884-8fa657c17ce1",
   "metadata": {},
   "source": [
    "## Preprocess Data, Create Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9348e944-7ebd-4d28-ae74-a6b2c2f116fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a40a4f19564d5eac44e2f610fb1cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/252 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71365826d504b63a67f3582a25d0c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/252 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sen1', 'sen2', 'ans'],\n",
       "        num_rows: 201168\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sen1', 'sen2', 'ans'],\n",
       "        num_rows: 50293\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.class_encode_column('ans')\n",
    "processed_dataset = dataset[\"train\"].train_test_split(test_size=0.2, stratify_by_column='ans')\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5307e4-ba33-4483-b396-64da49a800d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f31d1c-4a03-497d-955b-0cffa75d0f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    return tokenizer(examples[\"sen1\"], examples['sen2'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb35d3e-97ea-467f-87ca-da0c6d8700b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05631f788e54b1cb37c21a7fe817537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/202 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = processed_dataset.map(\n",
    "    preprocess_data,\n",
    "    remove_columns=(\"sen1\", \"sen2\"),\n",
    "    batched=True,\n",
    ").rename_column('ans', 'next_sentence_label')\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c1231d-e2ba-4731-9256-be6888f980c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Verify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01929557-8708-49d0-8377-8a3dcce01e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = tokenized_dataset['train'][3]\n",
    "example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f53959-845d-4073-8f1d-5aad8ac222eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(example[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9820a5-b315-4fc2-b01b-8b57ce1f377a",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595efe69-78aa-4cd4-938c-8d65c88e0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_fast uses fast tokenizers backed by rust. Remove it if it causes errors\n",
    "model = BertForNextSentencePrediction.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e970785-d836-4ffb-941e-d9c271ef6ce2",
   "metadata": {},
   "source": [
    "### Verify data-model interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999979a2-ee24-45e1-9433-7b9b001c9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "# outputs = model(\n",
    "# input_ids=tokenized_dataset[labels[0]][\"train\"][\"input_ids\"][0],\n",
    "# labels=tokenized_dataset[labels[0]][\"train\"][0][\"labels\"],\n",
    "# )\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24902ec3-5c93-48d6-a4ec-980cd327eee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ff917-8618-4bc2-819f-10da7b2849dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"accuracy\": evaluate.load(\"accuracy\"),\n",
    "    \"presicion\": evaluate.load(\"precision\"),\n",
    "    \"recall\": evaluate.load(\"recall\"),\n",
    "    \"f1\": evaluate.load(\"f1\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a724497-7a15-48f8-ba60-95f7d5f0c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    # print(eval_pred)\n",
    "    # print(list(eval_pred))\n",
    "    logits, labels = eval_pred\n",
    "    # print(logits, labels)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        name: metric.compute(predictions=predictions, references=labels)\n",
    "        for name, metric in metrics.items()\n",
    "    }\n",
    "\n",
    "def compute_best(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    val = metrics['f1'].compute(predictions=predictions, labels=labels)\n",
    "    print(val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716eedb7-f61e-471a-bd17-9750bfc07bdc",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc962c2-e601-4f0f-9261-4d2cd1af5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  # TODO: increase if we have more data\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ca33e-84bc-4672-bd83-262d4d6f7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    MODEL_NAME,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"all\",\n",
    "    label_names=['next_sentence_label'],\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd0e5c-fe03-4562-bd96-6755e5e749a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(3000))\n",
    "small_eval_dataset = tokenized_dataset[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e2f4b-051a-4de4-a09b-c71a7cdcc15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,  # tokenized_dataset[\"train\"],\n",
    "    eval_dataset=small_eval_dataset,  # tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,  # compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bc9b3-2cde-4db2-b6d3-9bc871cc9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b028df0-8be7-409e-a3ce-1c676eb1e9fa",
   "metadata": {},
   "source": [
    "## Upload the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a83e7a-b111-4b37-9e07-e3c7cf5ab00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free the memory\n",
    "gc.collect()\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "model = None\n",
    "trainer = None\n",
    "training_args = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b1085-f7d7-4a3f-a761-67053f8cc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agency-vs-rest/checkpoint-263: 0.75 precision, 0.85 recall\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003bb89c-8ee0-4bc6-9316-cce5ebd5ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
