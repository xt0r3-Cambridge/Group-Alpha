{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79688b38-ed00-4f35-b491-6a41e2433a6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# One-vs-Rest Classifier\n",
    "\n",
    "This notebook implements an one-vs-rest classifier that fine-tunes several BERT models to tell if a sentence contains problematic metaphors.\n",
    "\n",
    "<div hidden>\n",
    "TODO: add extend data3/data.json with better data in the same format that actually makes sense.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c329b4-dc31-4cd0-8058-b59015328184",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0b50b-c9ff-45b5-979a-c2fa5634ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -Uqq\n",
    "!pip install sklearn -Uqq\n",
    "!pip install datasets -Uqq\n",
    "!pip install torch -Uqq\n",
    "!pip install numpy -Uqq\n",
    "!pip install evaluate -Uqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01c2eb7-f752-4628-b88d-48576c6461ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c78698-ce72-41f7-96fb-111a4f1d3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"one-vs-rest-bert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ae221-1bbc-4a4a-8a1e-0feb9d17b57e",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898408be-0c15-4e58-9e7e-97fffccb4797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1a6ea59de8e07549\n",
      "Found cached dataset json (/home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b250a1368a410492ee8109b3bff7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'agency', 'humanComparison', 'hyperbole', 'historyComparison', 'unjustClaims', 'deepSounding', 'sceptics', 'deEmphasize', 'performanceNumber', 'inscrutable'],\n",
       "        num_rows: 329\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"data/data.json\", field=\"data\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b214393b-11e3-454e-b21f-a05ee38fefbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['A new vision of artificial intelligence for the people',\n",
       "  'The gig workers fighting back against the algorithms',\n",
       "  'How the AI industry profits from catastrophe'],\n",
       " 'agency': [False, True, False],\n",
       " 'humanComparison': [False, True, False],\n",
       " 'hyperbole': [False, True, True],\n",
       " 'historyComparison': [False, False, False],\n",
       " 'unjustClaims': [False, False, False],\n",
       " 'deepSounding': [False, False, False],\n",
       " 'sceptics': [False, False, False],\n",
       " 'deEmphasize': [False, False, False],\n",
       " 'performanceNumber': [False, False, False],\n",
       " 'inscrutable': [False, False, False]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce458fc2-c419-4b3c-b4aa-14571f7467e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agency',\n",
       " 'humanComparison',\n",
       " 'hyperbole',\n",
       " 'historyComparison',\n",
       " 'unjustClaims',\n",
       " 'deepSounding',\n",
       " 'sceptics',\n",
       " 'deEmphasize',\n",
       " 'performanceNumber',\n",
       " 'inscrutable']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label for label in dataset[\"train\"].features.keys() if label not in [\"text\"]]\n",
    "\n",
    "num_epochs = {\n",
    "    \"agency\": 10,\n",
    "    \"humanComparison\": 2,\n",
    "    \"hyperbole\": 2,\n",
    "    \"historyComparison\": 2,\n",
    "    \"unjustClaims\": 5,\n",
    "    \"deepSounding\": 2,\n",
    "    \"sceptics\": 2,\n",
    "    \"deEmphasize\": 7,\n",
    "    \"performanceNumber\": 2,\n",
    "    \"inscrutable\": 2,\n",
    "}\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514633be-491c-4f3c-a884-8fa657c17ce1",
   "metadata": {},
   "source": [
    "## Preprocess Data, Create Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9348e944-7ebd-4d28-ae74-a6b2c2f116fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-9888192aecf65689.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-a22d962d251fa119.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-6679ad177d2b3f10.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-ab913caaba2e0f37.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-e8fe16890ef7a28d.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7d3f6ee493d43134.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-6f1e24ac56528d5d.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-63a0d013af6f7b98.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-1a4568ab8a85143e.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-6e0de03583e9067e.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-47b6f35bb5df5119.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-a3c7e491b119ce42.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dcfd5833dd96b9c0.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-2510dc42a524489f.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-8c56660299517ba1.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-d1707640cb482ae9.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-5a43c3358bd4fe05.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-0441bd1acf9a7966.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-281478618d44f289.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-2cb1a5c0e7a49924.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-a324ca98536b6fa3.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-67d7a5cf14be05b5.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3a91667ffe35d117.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-935a902cdc1f5c7a.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-795a4a44e14e9e7e.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-a72d10c9d0944265.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-df479552a6d1eb16.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-0609263235c3d9e1.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-b61d990b6b85aea5.arrow\n",
      "Loading cached processed dataset at /home/xt0r3/.cache/huggingface/datasets/json/default-1a6ea59de8e07549/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-97d45774bc8a7c76.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'agency': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 263\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 66\n",
       "     })\n",
       " }),\n",
       " 'humanComparison': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 263\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 66\n",
       "     })\n",
       " }),\n",
       " 'hyperbole': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 263\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 66\n",
       "     })\n",
       " }),\n",
       " 'historyComparison': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 263\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 66\n",
       "     })\n",
       " }),\n",
       " 'unjustClaims': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 263\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 66\n",
       "     })\n",
       " }),\n",
       " 'deepSounding': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 263\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 66\n",
       "     })\n",
       " }),\n",
       " 'sceptics': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 263\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 66\n",
       "     })\n",
       " }),\n",
       " 'deEmphasize': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 263\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 66\n",
       "     })\n",
       " }),\n",
       " 'performanceNumber': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 263\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 66\n",
       "     })\n",
       " }),\n",
       " 'inscrutable': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 263\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'labels'],\n",
       "         num_rows: 66\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset = {}\n",
    "for label in labels:\n",
    "    projected_dataset = (\n",
    "        dataset[\"train\"]\n",
    "        .map(remove_columns=[l for l in labels if l != label])\n",
    "        .rename_column(label, \"labels\")\n",
    "        .class_encode_column(\"labels\")\n",
    "    )\n",
    "    processed_dataset[label] = projected_dataset.train_test_split(\n",
    "        test_size=0.2, stratify_by_column=\"labels\"\n",
    "    )\n",
    "    # print(f\"{label}:\\n\\t{processed_dataset[label]['test'][0:3]}\\n\")\n",
    "\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f31d1c-4a03-497d-955b-0cffa75d0f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb35d3e-97ea-467f-87ca-da0c6d8700b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ce708c0cd545098494aa62c3e039b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90131215c7445a6afd24fd2c2d13e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0fadc7a8f44e83a026b10afb9a5c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666d40d11ca74c358bd7121a2ec454e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8b6ecb4ace4c588e15287cc5afd6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9969833992471eb132a328f9d7978d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df3bd0389d34f29b10740c0f5e48c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6efd0e529d345349cbf543e3c9f4405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b043696ea3429790c29c11e785f82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3328a5bf31564a90b72b8c253ace3087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14aa95bd172349d994b1c2b3a55ff103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4da5a6e0294defae7b06b0e03241c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d954f94957747fe8743c0b1d3cb01fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7a7f6b6b4d4be3899e6fc2706db7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d323c90a904b4c03af7120316a94c117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5c3184baf34b75b8c9220726bc210f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093cc20529df4832893e08e852415f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6494e8b062574086856fd09d54734250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64de983d80e54d94accd2dd54213307f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a4a8d60c2840f2a26fd737ca560480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = {\n",
    "    k: ds.map(\n",
    "        preprocess_data,\n",
    "        remove_columns=\"text\",\n",
    "        batched=True,\n",
    "    )\n",
    "    for k, ds in processed_dataset.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c1231d-e2ba-4731-9256-be6888f980c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Verify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01929557-8708-49d0-8377-8a3dcce01e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "example = tokenized_dataset[\"agency\"][\"train\"][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f53959-845d-4073-8f1d-5aad8ac222eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] AI pioneer Geoff Hinton : “ Deep learning is going to be able to do everything ” [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8092ca8e-46fd-43ad-a7be-88e94055b695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9820a5-b315-4fc2-b01b-8b57ce1f377a",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "595efe69-78aa-4cd4-938c-8d65c88e0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_fast uses fast tokenizers backed by rust. Remove it if it causes errors\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    # \"bert-base-cased\",\n",
    "    # num_labels=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e970785-d836-4ffb-941e-d9c271ef6ce2",
   "metadata": {},
   "source": [
    "### Verify data-model interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "999979a2-ee24-45e1-9433-7b9b001c9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "# outputs = model(\n",
    "# input_ids=tokenized_dataset[labels[0]][\"train\"][\"input_ids\"][0],\n",
    "# labels=tokenized_dataset[labels[0]][\"train\"][0][\"labels\"],\n",
    "# )\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24902ec3-5c93-48d6-a4ec-980cd327eee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "059ff917-8618-4bc2-819f-10da7b2849dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"accuracy\": evaluate.load(\"accuracy\"),\n",
    "    \"presicion\": evaluate.load(\"precision\"),\n",
    "    \"recall\": evaluate.load(\"recall\"),\n",
    "    \"f1\": evaluate.load(\"f1\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a724497-7a15-48f8-ba60-95f7d5f0c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        name: metric.compute(predictions=predictions, references=labels)\n",
    "        for name, metric in metrics.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3493053e-1b83-458c-bbd6-6bbe1140705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighPrecisionTrainer(Trainer):\n",
    "    \"\"\"A trainer class, which computes loss based on a weighted MSE, where the error for the positive labels is\n",
    "    weighted more than the error for the negative labels, leading to a higher precision\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        label_mask = torch.FloatTensor(1, 2).cuda().zero_()\n",
    "        label_mask[0, labels[0]] = 1\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        loss = torch.sum(torch.tensor([[1, 300]]).cuda() * ((logits - label_mask) ** 2))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716eedb7-f61e-471a-bd17-9750bfc07bdc",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fc962c2-e601-4f0f-9261-4d2cd1af5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  # TODO: increase if we have more data\n",
    "# metric_name = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa6bc9b3-2cde-4db2-b6d3-9bc871cc9802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for agency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2630\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2630' max='2630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2630/2630 04:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Presicion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.072770</td>\n",
       "      <td>{'accuracy': 0.7878787878787878}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.003500</td>\n",
       "      <td>1.108384</td>\n",
       "      <td>{'accuracy': 0.7878787878787878}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.003500</td>\n",
       "      <td>0.961167</td>\n",
       "      <td>{'accuracy': 0.7878787878787878}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>1.390078</td>\n",
       "      <td>{'accuracy': 0.803030303030303}</td>\n",
       "      <td>{'precision': 0.5714285714285714}</td>\n",
       "      <td>{'recall': 0.2857142857142857}</td>\n",
       "      <td>{'f1': 0.38095238095238093}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>1.762271</td>\n",
       "      <td>{'accuracy': 0.7575757575757576}</td>\n",
       "      <td>{'precision': 0.4}</td>\n",
       "      <td>{'recall': 0.2857142857142857}</td>\n",
       "      <td>{'f1': 0.3333333333333333}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.696432</td>\n",
       "      <td>{'accuracy': 0.8181818181818182}</td>\n",
       "      <td>{'precision': 0.6666666666666666}</td>\n",
       "      <td>{'recall': 0.2857142857142857}</td>\n",
       "      <td>{'f1': 0.4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.786655</td>\n",
       "      <td>{'accuracy': 0.803030303030303}</td>\n",
       "      <td>{'precision': 0.5714285714285714}</td>\n",
       "      <td>{'recall': 0.2857142857142857}</td>\n",
       "      <td>{'f1': 0.38095238095238093}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.815185</td>\n",
       "      <td>{'accuracy': 0.803030303030303}</td>\n",
       "      <td>{'precision': 0.5714285714285714}</td>\n",
       "      <td>{'recall': 0.2857142857142857}</td>\n",
       "      <td>{'f1': 0.38095238095238093}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.834082</td>\n",
       "      <td>{'accuracy': 0.803030303030303}</td>\n",
       "      <td>{'precision': 0.5714285714285714}</td>\n",
       "      <td>{'recall': 0.2857142857142857}</td>\n",
       "      <td>{'f1': 0.38095238095238093}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.906452</td>\n",
       "      <td>{'accuracy': 0.803030303030303}</td>\n",
       "      <td>{'precision': 0.5714285714285714}</td>\n",
       "      <td>{'recall': 0.2857142857142857}</td>\n",
       "      <td>{'f1': 0.38095238095238093}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_agency-vs-rest/checkpoint-263\n",
      "Configuration saved in aihype_agency-vs-rest/checkpoint-263/config.json\n",
      "Model weights saved in aihype_agency-vs-rest/checkpoint-263/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_agency-vs-rest/checkpoint-526\n",
      "Configuration saved in aihype_agency-vs-rest/checkpoint-526/config.json\n",
      "Model weights saved in aihype_agency-vs-rest/checkpoint-526/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_agency-vs-rest/checkpoint-789\n",
      "Configuration saved in aihype_agency-vs-rest/checkpoint-789/config.json\n",
      "Model weights saved in aihype_agency-vs-rest/checkpoint-789/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_agency-vs-rest/checkpoint-1052\n",
      "Configuration saved in aihype_agency-vs-rest/checkpoint-1052/config.json\n",
      "Model weights saved in aihype_agency-vs-rest/checkpoint-1052/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_agency-vs-rest/checkpoint-1315\n",
      "Configuration saved in aihype_agency-vs-rest/checkpoint-1315/config.json\n",
      "Model weights saved in aihype_agency-vs-rest/checkpoint-1315/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_agency-vs-rest/checkpoint-1578\n",
      "Configuration saved in aihype_agency-vs-rest/checkpoint-1578/config.json\n",
      "Model weights saved in aihype_agency-vs-rest/checkpoint-1578/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_agency-vs-rest/checkpoint-1841\n",
      "Configuration saved in aihype_agency-vs-rest/checkpoint-1841/config.json\n",
      "Model weights saved in aihype_agency-vs-rest/checkpoint-1841/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_agency-vs-rest/checkpoint-2104\n",
      "Configuration saved in aihype_agency-vs-rest/checkpoint-2104/config.json\n",
      "Model weights saved in aihype_agency-vs-rest/checkpoint-2104/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_agency-vs-rest/checkpoint-2367\n",
      "Configuration saved in aihype_agency-vs-rest/checkpoint-2367/config.json\n",
      "Model weights saved in aihype_agency-vs-rest/checkpoint-2367/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_agency-vs-rest/checkpoint-2630\n",
      "Configuration saved in aihype_agency-vs-rest/checkpoint-2630/config.json\n",
      "Model weights saved in aihype_agency-vs-rest/checkpoint-2630/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for humanComparison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 526\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='526' max='526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [526/526 00:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Presicion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.557540</td>\n",
       "      <td>{'accuracy': 0.9090909090909091}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.531200</td>\n",
       "      <td>0.545151</td>\n",
       "      <td>{'accuracy': 0.9090909090909091}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_humanComparison-vs-rest/checkpoint-263\n",
      "Configuration saved in aihype_humanComparison-vs-rest/checkpoint-263/config.json\n",
      "Model weights saved in aihype_humanComparison-vs-rest/checkpoint-263/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_humanComparison-vs-rest/checkpoint-526\n",
      "Configuration saved in aihype_humanComparison-vs-rest/checkpoint-526/config.json\n",
      "Model weights saved in aihype_humanComparison-vs-rest/checkpoint-526/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for hyperbole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 526\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='526' max='526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [526/526 00:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Presicion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.600864</td>\n",
       "      <td>{'accuracy': 0.9090909090909091}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.599683</td>\n",
       "      <td>{'accuracy': 0.9090909090909091}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_hyperbole-vs-rest/checkpoint-263\n",
      "Configuration saved in aihype_hyperbole-vs-rest/checkpoint-263/config.json\n",
      "Model weights saved in aihype_hyperbole-vs-rest/checkpoint-263/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_hyperbole-vs-rest/checkpoint-526\n",
      "Configuration saved in aihype_hyperbole-vs-rest/checkpoint-526/config.json\n",
      "Model weights saved in aihype_hyperbole-vs-rest/checkpoint-526/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for historyComparison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 526\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='526' max='526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [526/526 00:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Presicion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.120591</td>\n",
       "      <td>{'accuracy': 0.9848484848484849}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>{'accuracy': 0.9848484848484849}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_historyComparison-vs-rest/checkpoint-263\n",
      "Configuration saved in aihype_historyComparison-vs-rest/checkpoint-263/config.json\n",
      "Model weights saved in aihype_historyComparison-vs-rest/checkpoint-263/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_historyComparison-vs-rest/checkpoint-526\n",
      "Configuration saved in aihype_historyComparison-vs-rest/checkpoint-526/config.json\n",
      "Model weights saved in aihype_historyComparison-vs-rest/checkpoint-526/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for unjustClaims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1315\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1315' max='1315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1315/1315 02:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Presicion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.379984</td>\n",
       "      <td>{'accuracy': 0.9393939393939394}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.433900</td>\n",
       "      <td>0.373176</td>\n",
       "      <td>{'accuracy': 0.9393939393939394}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.433900</td>\n",
       "      <td>0.399645</td>\n",
       "      <td>{'accuracy': 0.9393939393939394}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>0.402784</td>\n",
       "      <td>{'accuracy': 0.9393939393939394}</td>\n",
       "      <td>{'precision': 0.5}</td>\n",
       "      <td>{'recall': 0.25}</td>\n",
       "      <td>{'f1': 0.3333333333333333}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>0.426157</td>\n",
       "      <td>{'accuracy': 0.9393939393939394}</td>\n",
       "      <td>{'precision': 0.5}</td>\n",
       "      <td>{'recall': 0.25}</td>\n",
       "      <td>{'f1': 0.3333333333333333}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_unjustClaims-vs-rest/checkpoint-263\n",
      "Configuration saved in aihype_unjustClaims-vs-rest/checkpoint-263/config.json\n",
      "Model weights saved in aihype_unjustClaims-vs-rest/checkpoint-263/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_unjustClaims-vs-rest/checkpoint-526\n",
      "Configuration saved in aihype_unjustClaims-vs-rest/checkpoint-526/config.json\n",
      "Model weights saved in aihype_unjustClaims-vs-rest/checkpoint-526/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_unjustClaims-vs-rest/checkpoint-789\n",
      "Configuration saved in aihype_unjustClaims-vs-rest/checkpoint-789/config.json\n",
      "Model weights saved in aihype_unjustClaims-vs-rest/checkpoint-789/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_unjustClaims-vs-rest/checkpoint-1052\n",
      "Configuration saved in aihype_unjustClaims-vs-rest/checkpoint-1052/config.json\n",
      "Model weights saved in aihype_unjustClaims-vs-rest/checkpoint-1052/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_unjustClaims-vs-rest/checkpoint-1315\n",
      "Configuration saved in aihype_unjustClaims-vs-rest/checkpoint-1315/config.json\n",
      "Model weights saved in aihype_unjustClaims-vs-rest/checkpoint-1315/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for deepSounding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 526\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='526' max='526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [526/526 00:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Presicion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.236281</td>\n",
       "      <td>{'accuracy': 0.9696969696969697}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>0.223143</td>\n",
       "      <td>{'accuracy': 0.9696969696969697}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_deepSounding-vs-rest/checkpoint-263\n",
      "Configuration saved in aihype_deepSounding-vs-rest/checkpoint-263/config.json\n",
      "Model weights saved in aihype_deepSounding-vs-rest/checkpoint-263/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_deepSounding-vs-rest/checkpoint-526\n",
      "Configuration saved in aihype_deepSounding-vs-rest/checkpoint-526/config.json\n",
      "Model weights saved in aihype_deepSounding-vs-rest/checkpoint-526/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for sceptics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 526\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='526' max='526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [526/526 00:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Presicion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>{'accuracy': 1.0}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>{'accuracy': 1.0}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "Saving model checkpoint to aihype_sceptics-vs-rest/checkpoint-263\n",
      "Configuration saved in aihype_sceptics-vs-rest/checkpoint-263/config.json\n",
      "Model weights saved in aihype_sceptics-vs-rest/checkpoint-263/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "Saving model checkpoint to aihype_sceptics-vs-rest/checkpoint-526\n",
      "Configuration saved in aihype_sceptics-vs-rest/checkpoint-526/config.json\n",
      "Model weights saved in aihype_sceptics-vs-rest/checkpoint-526/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for deEmphasize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1841\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1841' max='1841' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1841/1841 03:20, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Presicion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.432795</td>\n",
       "      <td>{'accuracy': 0.9242424242424242}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>0.346446</td>\n",
       "      <td>{'accuracy': 0.9242424242424242}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>0.514109</td>\n",
       "      <td>{'accuracy': 0.9242424242424242}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.688440</td>\n",
       "      <td>{'accuracy': 0.9242424242424242}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.722558</td>\n",
       "      <td>{'accuracy': 0.8787878787878788}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.824340</td>\n",
       "      <td>{'accuracy': 0.8636363636363636}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.915698</td>\n",
       "      <td>{'accuracy': 0.8787878787878788}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_deEmphasize-vs-rest/checkpoint-263\n",
      "Configuration saved in aihype_deEmphasize-vs-rest/checkpoint-263/config.json\n",
      "Model weights saved in aihype_deEmphasize-vs-rest/checkpoint-263/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_deEmphasize-vs-rest/checkpoint-526\n",
      "Configuration saved in aihype_deEmphasize-vs-rest/checkpoint-526/config.json\n",
      "Model weights saved in aihype_deEmphasize-vs-rest/checkpoint-526/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_deEmphasize-vs-rest/checkpoint-789\n",
      "Configuration saved in aihype_deEmphasize-vs-rest/checkpoint-789/config.json\n",
      "Model weights saved in aihype_deEmphasize-vs-rest/checkpoint-789/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_deEmphasize-vs-rest/checkpoint-1052\n",
      "Configuration saved in aihype_deEmphasize-vs-rest/checkpoint-1052/config.json\n",
      "Model weights saved in aihype_deEmphasize-vs-rest/checkpoint-1052/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_deEmphasize-vs-rest/checkpoint-1315\n",
      "Configuration saved in aihype_deEmphasize-vs-rest/checkpoint-1315/config.json\n",
      "Model weights saved in aihype_deEmphasize-vs-rest/checkpoint-1315/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_deEmphasize-vs-rest/checkpoint-1578\n",
      "Configuration saved in aihype_deEmphasize-vs-rest/checkpoint-1578/config.json\n",
      "Model weights saved in aihype_deEmphasize-vs-rest/checkpoint-1578/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to aihype_deEmphasize-vs-rest/checkpoint-1841\n",
      "Configuration saved in aihype_deEmphasize-vs-rest/checkpoint-1841/config.json\n",
      "Model weights saved in aihype_deEmphasize-vs-rest/checkpoint-1841/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for performanceNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 526\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='526' max='526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [526/526 00:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Presicion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.126803</td>\n",
       "      <td>{'accuracy': 0.9848484848484849}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>0.134051</td>\n",
       "      <td>{'accuracy': 0.9848484848484849}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_performanceNumber-vs-rest/checkpoint-263\n",
      "Configuration saved in aihype_performanceNumber-vs-rest/checkpoint-263/config.json\n",
      "Model weights saved in aihype_performanceNumber-vs-rest/checkpoint-263/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_performanceNumber-vs-rest/checkpoint-526\n",
      "Configuration saved in aihype_performanceNumber-vs-rest/checkpoint-526/config.json\n",
      "Model weights saved in aihype_performanceNumber-vs-rest/checkpoint-526/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for inscrutable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/xt0r3/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 526\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='526' max='526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [526/526 00:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Presicion</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.126697</td>\n",
       "      <td>{'accuracy': 0.9848484848484849}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.138472</td>\n",
       "      <td>{'accuracy': 0.9848484848484849}</td>\n",
       "      <td>{'precision': 0.0}</td>\n",
       "      <td>{'recall': 0.0}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_inscrutable-vs-rest/checkpoint-263\n",
      "Configuration saved in aihype_inscrutable-vs-rest/checkpoint-263/config.json\n",
      "Model weights saved in aihype_inscrutable-vs-rest/checkpoint-263/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 1\n",
      "/home/xt0r3/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to aihype_inscrutable-vs-rest/checkpoint-526\n",
      "Configuration saved in aihype_inscrutable-vs-rest/checkpoint-526/config.json\n",
      "Model weights saved in aihype_inscrutable-vs-rest/checkpoint-526/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(f\"training model for {label}\")\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-cased\",\n",
    "        num_labels=2,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        f\"aihype_{label}-vs-rest\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs[label],\n",
    "        # weight_decay=0.05,\n",
    "        report_to=\"all\",\n",
    "        # load_best_model_at_end=True,\n",
    "        # metric_for_best_model=metric_name,\n",
    "        # push_to_hub=True,  # TODO: enable once model seems good\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[label][\"train\"],\n",
    "        eval_dataset=tokenized_dataset[label][\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b028df0-8be7-409e-a3ce-1c676eb1e9fa",
   "metadata": {},
   "source": [
    "## Upload the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "315b1085-f7d7-4a3f-a761-67053f8cc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agency-vs-rest/checkpoint-263: 0.75 precision, 0.85 recall\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "003bb89c-8ee0-4bc6-9316-cce5ebd5ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
