{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34645bc6-d38b-4f63-bd22-d43942fe9626",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testing the Machine Learning Model\n",
    "\n",
    "I will keep this notebook updated in a way that it can always be used to test the newest version of the NLP model for classifying AI headlines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b347dbb-274b-4e79-9a89-93117e839977",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea6011-e8a4-405a-87b3-90c970da2324",
   "metadata": {},
   "source": [
    "1. You need to train the model on your computer beforehand, or ask Kornel for the model weights. You can train the model by running `classifier.ipynb`. It is going to take a couple hours if run on a normal laptop without a GPU. With a GPU it should be in about 10 minutes.\n",
    "    - **NOTE**: You might need to change the `MODEL_PATH` variable.\n",
    "2. If you run all cells of this notebook in order, the bottom cell will launch an interactive interface which can be used to interactively test the model or issue API calls to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7a8aa4-592d-40c8-a121-c7cd921e3695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Kornel TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b21f299-d00e-44c0-99fc-557252e2b011",
   "metadata": {},
   "source": [
    "TODO: Check our [multi-label case](https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb)\n",
    "\n",
    "[this](https://github.com/Dirkster99/PyNotes/blob/master/Transformers/LocalModelUsage_Finetuning/30%20MultiClass%20Classification%20in%2010%20Minutes%20with%20BERT-TensorFlow-SoftMax-LocalModel.ipynb) may help too?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b14664-d3b2-4898-b785-a57a56418f18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ef3181-fe37-4027-93ac-ab1f9fb5873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Updates the transformers library to the latest version. WARNING: If you don't have it installed, it's a couple GBs of data.\n",
    "!pip install -Uqq transformers\n",
    "!pip install -Uqq gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e658978-6c3f-4c9e-aec8-4dbee296ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import gradio as gr\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    TextClassificationPipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8b0a6-49b3-489f-83b2-f90f81ef9f60",
   "metadata": {},
   "source": [
    "### Set Model Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed78c2d0-daa5-4105-8b38-af1db8888dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"test_trainer/checkpoint-500/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41df128-d569-4f8d-91c6-b340ab04294b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "852eb153-8a8b-44bd-83e1-cd3c4c856bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LABEL_0': 'agency',\n",
       " 'LABEL_1': 'humanComparison',\n",
       " 'LABEL_2': 'hyperbole',\n",
       " 'LABEL_3': 'historyComparison',\n",
       " 'LABEL_4': 'unjustClaims',\n",
       " 'LABEL_5': 'deepSounding',\n",
       " 'LABEL_6': 'skeptics',\n",
       " 'LABEL_7': 'deEmphasize',\n",
       " 'LABEL_8': 'performanceNumber',\n",
       " 'LABEL_9': 'inscrutable',\n",
       " 'LABEL_10': 'objective'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = {}\n",
    "\n",
    "with open(\"data/data.json\") as f:\n",
    "    d = json.load(f)\n",
    "    for i, name in enumerate(d.keys()):\n",
    "        names[f\"LABEL_{i}\"] = name\n",
    "\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947e782d-6f89-48e4-b625-67174ba48f0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8076111a-263c-4701-89f8-97b982f0e3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xt0r3/.local/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "pipe = TextClassificationPipeline(\n",
    "    model=model, tokenizer=tokenizer, return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e97eab7-3020-4bcb-9433-482603349148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    pred_dict = dict()\n",
    "    preds = pipe(text)[0]\n",
    "    preds = {\n",
    "        k: v\n",
    "        for d in map(lambda pred: {names[pred[\"label\"]]: pred[\"score\"]}, preds)\n",
    "        for k, v in d.items()\n",
    "    }\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "841636b7-98ef-4753-a257-cd4ed187e1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agency': 0.0001564613776281476,\n",
       " 'humanComparison': 0.0009414521045982838,\n",
       " 'hyperbole': 0.0003454808611422777,\n",
       " 'historyComparison': 0.0010318453423678875,\n",
       " 'unjustClaims': 0.0004964807303622365,\n",
       " 'deepSounding': 0.99512779712677,\n",
       " 'skeptics': 0.0005015040514990687,\n",
       " 'deEmphasize': 8.166562474798411e-05,\n",
       " 'performanceNumber': 0.00028639606898650527,\n",
       " 'inscrutable': 0.00028850772650912404,\n",
       " 'objective': 0.0007424494251608849}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict scores\n",
    "predict(\"Machine Learning is at the forefront of education, replacing human jobs\")\n",
    "# Note that it does a weird prediction, saying that this is a deep-sounding headline, even though it also attributes agency, compares it with humans, uses the hyperbole and\n",
    "# has unjust claims in the headline.\n",
    "# TODO: Find a model suitable for multiple classification?\n",
    "# Check out https://discuss.huggingface.co/t/fine-tune-for-multiclass-or-multilabel-multiclass/4035\n",
    "# Even better: https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ffa715-84ce-425a-95e5-318d39e3c6b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Launching online interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a431be20-399d-4e03-9218-04735199ea45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    \"Machine Learning is at the forefront of education, replacing human jobs\",\n",
    "    \"AI model leaves scientists confused\",\n",
    "    \"This model is not really cool\",\n",
    "]\n",
    "\n",
    "intf = gr.Interface(fn=predict, inputs=\"textbox\", outputs=\"label\", examples=examples)\n",
    "intf.launch(inline=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
